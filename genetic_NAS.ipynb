{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n",
      "3703 6\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='/data/CiteSeer', name='CiteSeer')\n",
    "print(len(dataset))\n",
    "data = dataset[0]\n",
    "data = data.to(device)\n",
    "print(data)\n",
    "num_node_features, num_classes = dataset.num_node_features, dataset.num_classes\n",
    "print(num_node_features, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch_geometric.nn as gnn\n",
    "#gene: conv_type1, hidden_size, dropout1, conv_type2, dropout2\n",
    "#conv_type: GCN, GIN, GAT, Cheb, Sage, K-GNN, fc \n",
    "hidden_choices = [8, 16, 32, 64, 128]\n",
    "dropout_choices = [0.01, 0.25, 0.5, 0.75]\n",
    "\n",
    "def generate_gene():\n",
    "    ans = {}\n",
    "    ans[\"conv_type1\"] = np.random.randint(0, 7)\n",
    "    ans[\"hidden_size\"] = random.choice(hidden_choices)\n",
    "    ans[\"dropout1\"] = random.choice(dropout_choices)\n",
    "    ans[\"conv_type2\"] = np.random.randint(0, 7)\n",
    "    ans[\"dropout2\"] = random.choice(dropout_choices)\n",
    "    return ans\n",
    "\n",
    "def generate_population(num):\n",
    "    return [generate_gene() for i in range(num)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerchoice(layernum, in_channel, out_channel):\n",
    "    if layernum == 1:\n",
    "        return gnn.GINConv(nn=nn.Linear(in_channel, out_channel), eps=1e-9)\n",
    "    elif layernum == 2:\n",
    "        return gnn.GATConv(in_channel, out_channel)\n",
    "    elif layernum == 3:\n",
    "        return gnn.ChebConv(in_channel, out_channel, K=2)\n",
    "    elif layernum == 4:\n",
    "        return gnn.SAGEConv(in_channel, out_channel)\n",
    "    elif layernum == 5:\n",
    "        return gnn.GraphConv(in_channel, out_channel)\n",
    "    elif layernum == 6:\n",
    "        '''conv = gnn.GENConv(in_channel, out_channel, aggr='softmax',\n",
    "                           t=1.0, learn_t=True, num_layers=2, norm='layer')\n",
    "        act = nn.ReLU(inplace=True)\n",
    "        return gnn.DeepGCNLayer(conv=conv, act=act, block='res+')'''\n",
    "        return gnn.TransformerConv(in_channel, out_channel)\n",
    "    else: #layernum == 0 or default\n",
    "        return gnn.GCNConv(in_channel, out_channel)\n",
    "\n",
    "class MyGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, gene):\n",
    "        super(MyGNN, self).__init__()\n",
    "        hidden_size = 16 #default\n",
    "        if \"hidden_size\" in gene:\n",
    "            hidden_size = gene[\"hidden_size\"]\n",
    "        else:\n",
    "            print(\"MyGNN init: hidden_size not in gene, choose 16 as default\")\n",
    "\n",
    "        self.conv1 = None\n",
    "        if \"conv_type1\" not in gene:\n",
    "            print(\"MyGNN init: conv_type1 not in gene, choose GCNConv as default\")\n",
    "            self.conv1 = gnn.GCNConv(in_channels, hidden_size)\n",
    "        else:\n",
    "            self.conv1 = layerchoice(gene[\"conv_type1\"], in_channels, hidden_size)\n",
    "        self.dropout1 = None\n",
    "        if \"dropout1\" in gene:\n",
    "            self.dropout1 = nn.Dropout(p=gene[\"dropout1\"])\n",
    "        else:\n",
    "            print(\"MyGNN init: dropout1 not in gene, choose p=0.01 as default\")\n",
    "            self.dropout1 = nn.Dropout(p=0.01)\n",
    "\n",
    "        self.conv2 = None\n",
    "        if \"conv_type2\" not in gene:\n",
    "            print(\"MyGNN init: conv_type2 not in gene, choose GCNConv as default\")\n",
    "            self.conv2 = gnn.GCNConv(hidden_size, out_channels)\n",
    "        else:\n",
    "            self.conv2 = layerchoice(gene[\"conv_type2\"], hidden_size, out_channels)\n",
    "        self.dropout2 = None\n",
    "        if \"dropout2\" in gene:\n",
    "            self.dropout2 = nn.Dropout(p=gene[\"dropout2\"])\n",
    "        else:\n",
    "            print(\"MyGNN init: dropout2 not in gene, choose p=0.01 as default\")\n",
    "            self.dropout2 = nn.Dropout(p=0.01)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_gene(gene, epochs=200, myprint=False):\n",
    "    print(gene)\n",
    "    model = MyGNN(num_node_features, num_classes, gene).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    loss_function = torch.nn.CrossEntropyLoss().to(device)\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_function(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        '''if myprint and epoch % 50 == 0:\n",
    "            print(\"epoch {}, loss = {}\".format(epoch, loss))'''\n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.val_mask] == data.y[data.val_mask]).sum()\n",
    "    acc = int(correct) / int(data.val_mask.sum())\n",
    "    if myprint:\n",
    "        print(f'Accuracy: {acc:.4f}')\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genetic(population=8, iters = 20, mutation_rate=0.05):\n",
    "    genes = generate_population(population)\n",
    "    bestscore = []\n",
    "    for iter in range(iters):\n",
    "        scores = [eval_gene(g) for g in genes]\n",
    "        print(scores)\n",
    "        bestscore.append(max(scores))\n",
    "        #choose highest half scores\n",
    "        survive = np.argsort(-np.array(scores))[:population//2]\n",
    "        genes = [genes[i] for i in survive]\n",
    "        if (iter+1) % 1 == 0 or iter == iters-1:\n",
    "            print(\"iteration=\", str(iter+1), \", best parameters is\", genes[0])\n",
    "            print(\"accuracy is {:.2%}\".format(bestscore[-1]))\n",
    "        if iter == iters-1:\n",
    "            break\n",
    "        random.shuffle(genes)\n",
    "        for i in range(len(genes)//2):\n",
    "            g1, g2 = genes[i].copy(), genes[i+1].copy()\n",
    "            #两两交配，完全打乱\n",
    "            if np.random.randint(0,2):\n",
    "                g1[\"conv_type1\"], g2[\"conv_type1\"] = g2[\"conv_type1\"], g1[\"conv_type1\"]\n",
    "            if np.random.randint(0,2):\n",
    "                g1[\"hidden_size\"], g2[\"hidden_size\"] = g2[\"hidden_size\"], g1[\"hidden_size\"]\n",
    "            if np.random.randint(0,2):\n",
    "                g1[\"dropout1\"], g2[\"dropout1\"] = g2[\"dropout1\"], g1[\"dropout1\"]\n",
    "            if np.random.randint(0,2):\n",
    "                g1[\"conv_type2\"], g2[\"conv_type2\"] = g2[\"conv_type2\"], g1[\"conv_type2\"]\n",
    "            if np.random.randint(0,2):\n",
    "                g1[\"dropout2\"], g2[\"dropout2\"] = g2[\"dropout2\"], g1[\"dropout2\"]\n",
    "            genes.append(g1)\n",
    "            genes.append(g2)\n",
    "        while len(genes) < population:\n",
    "            #e.g. population = 9 and after an iteration, population is 8\n",
    "            genes.append(generate_gene())\n",
    "        #mutation\n",
    "        for i in range(population):\n",
    "            if random.random() < mutation_rate:\n",
    "                genes[i][\"conv_type1\"] = np.random.randint(0, 7)\n",
    "            if random.random() < mutation_rate:\n",
    "                genes[i][\"hidden_size\"] = random.choice(hidden_choices)\n",
    "            if random.random() < mutation_rate:\n",
    "                genes[i][\"dropout1\"] = max(0.01, min(0.99, genes[i][\"dropout1\"] + np.random.normal(scale=0.1)))\n",
    "            if random.random() < mutation_rate:\n",
    "                genes[i][\"conv_type2\"] = np.random.randint(0, 7)\n",
    "            if random.random() < mutation_rate:\n",
    "                genes[i][\"dropout2\"] = max(0.01, min(0.99, genes[i][\"dropout2\"] + np.random.normal(scale=0.1)))\n",
    "\n",
    "    print(\"algorithm finished\")\n",
    "    plt.plot(list(range(1, iters+1)), bestscore)\n",
    "    plt.title(\"score of best parameters\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'conv_type1': 6, 'hidden_size': 32, 'dropout1': 0.75, 'conv_type2': 3, 'dropout2': 0.75}\n",
      "{'conv_type1': 1, 'hidden_size': 32, 'dropout1': 0.25, 'conv_type2': 1, 'dropout2': 0.01}\n",
      "{'conv_type1': 4, 'hidden_size': 32, 'dropout1': 0.5, 'conv_type2': 3, 'dropout2': 0.5}\n",
      "{'conv_type1': 2, 'hidden_size': 8, 'dropout1': 0.5, 'conv_type2': 2, 'dropout2': 0.75}\n",
      "{'conv_type1': 5, 'hidden_size': 8, 'dropout1': 0.25, 'conv_type2': 3, 'dropout2': 0.5}\n",
      "{'conv_type1': 3, 'hidden_size': 128, 'dropout1': 0.5, 'conv_type2': 2, 'dropout2': 0.25}\n",
      "{'conv_type1': 6, 'hidden_size': 8, 'dropout1': 0.25, 'conv_type2': 0, 'dropout2': 0.25}\n",
      "{'conv_type1': 4, 'hidden_size': 128, 'dropout1': 0.01, 'conv_type2': 5, 'dropout2': 0.5}\n",
      "iteration= 1 , best parameters is {'conv_type1': 3, 'hidden_size': 128, 'dropout1': 0.5, 'conv_type2': 2, 'dropout2': 0.25}\n",
      "accuracy is 67.80%\n",
      "{'conv_type1': 3, 'hidden_size': 128, 'dropout1': 0.5, 'conv_type2': 2, 'dropout2': 0.25}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m genetic()\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36mgenetic\u001b[1;34m(population, iters, mutation_rate)\u001b[0m\n\u001b[0;32m      3\u001b[0m bestscore \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iters):\n\u001b[1;32m----> 5\u001b[0m     scores \u001b[39m=\u001b[39m [eval_gene(g) \u001b[39mfor\u001b[39;49;00m g \u001b[39min\u001b[39;49;00m genes]\n\u001b[0;32m      6\u001b[0m     bestscore\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m(scores))\n\u001b[0;32m      7\u001b[0m     \u001b[39m#choose highest half scores\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 5\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      3\u001b[0m bestscore \u001b[39m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(iters):\n\u001b[1;32m----> 5\u001b[0m     scores \u001b[39m=\u001b[39m [eval_gene(g) \u001b[39mfor\u001b[39;00m g \u001b[39min\u001b[39;00m genes]\n\u001b[0;32m      6\u001b[0m     bestscore\u001b[39m.\u001b[39mappend(\u001b[39mmax\u001b[39m(scores))\n\u001b[0;32m      7\u001b[0m     \u001b[39m#choose highest half scores\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[5], line 9\u001b[0m, in \u001b[0;36meval_gene\u001b[1;34m(gene, epochs, myprint)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(epochs):\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m     out \u001b[39m=\u001b[39m model(data)\n\u001b[0;32m     10\u001b[0m     loss \u001b[39m=\u001b[39m loss_function(out[data\u001b[39m.\u001b[39mtrain_mask], data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask])\n\u001b[0;32m     11\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\mydl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[1;32mIn[4], line 61\u001b[0m, in \u001b[0;36mMyGNN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     59\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     60\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout1(x)\n\u001b[1;32m---> 61\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(x, edge_index)\n\u001b[0;32m     62\u001b[0m x \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m     63\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout2(x)\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\mydl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\mydl\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gat_conv.py:239\u001b[0m, in \u001b[0;36mGATConv.forward\u001b[1;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[0;32m    236\u001b[0m     num_nodes \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(size) \u001b[39mif\u001b[39;00m size \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m num_nodes\n\u001b[0;32m    237\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m remove_self_loops(\n\u001b[0;32m    238\u001b[0m         edge_index, edge_attr)\n\u001b[1;32m--> 239\u001b[0m     edge_index, edge_attr \u001b[39m=\u001b[39m add_self_loops(\n\u001b[0;32m    240\u001b[0m         edge_index, edge_attr, fill_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfill_value,\n\u001b[0;32m    241\u001b[0m         num_nodes\u001b[39m=\u001b[39;49mnum_nodes)\n\u001b[0;32m    242\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(edge_index, SparseTensor):\n\u001b[0;32m    243\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_dim \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32md:\\ProgramData\\Anaconda3\\envs\\mydl\\Lib\\site-packages\\torch_geometric\\utils\\loop.py:167\u001b[0m, in \u001b[0;36madd_self_loops\u001b[1;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[39m@torch\u001b[39m\u001b[39m.\u001b[39mjit\u001b[39m.\u001b[39m_overload\n\u001b[0;32m    162\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_self_loops\u001b[39m(edge_index, edge_attr, fill_value, num_nodes):\n\u001b[0;32m    163\u001b[0m     \u001b[39m# type: (Tensor, OptTensor, Optional[str], Optional[Tuple[int, int]]) -> Tuple[Tensor, OptTensor]  # noqa\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m--> 167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madd_self_loops\u001b[39m(\n\u001b[0;32m    168\u001b[0m     edge_index: Tensor,\n\u001b[0;32m    169\u001b[0m     edge_attr: OptTensor \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    170\u001b[0m     fill_value: Optional[Union[\u001b[39mfloat\u001b[39m, Tensor, \u001b[39mstr\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    171\u001b[0m     num_nodes: Optional[Union[\u001b[39mint\u001b[39m, Tuple[\u001b[39mint\u001b[39m, \u001b[39mint\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    172\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Tensor, OptTensor]:\n\u001b[0;32m    173\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Adds a self-loop :math:`(i,i) \\in \\mathcal{E}` to every node\u001b[39;00m\n\u001b[0;32m    174\u001b[0m \u001b[39m    :math:`i \\in \\mathcal{V}` in the graph given by :attr:`edge_index`.\u001b[39;00m\n\u001b[0;32m    175\u001b[0m \u001b[39m    In case the graph is weighted or has multi-dimensional edge features\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m        tensor([0.5000, 0.5000, 0.5000, 1.0000, 0.5000]))\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m     layout: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "genetic()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
