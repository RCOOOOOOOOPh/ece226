{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "1\n",
      "Data(x=[3327, 3703], edge_index=[2, 9104], y=[3327], train_mask=[3327], val_mask=[3327], test_mask=[3327])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(root='/data/CiteSeer', name='CiteSeer')\n",
    "print(len(dataset))\n",
    "data = dataset[0]\n",
    "data = data.to(device)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import nni.retiarii.nn.pytorch as nn\n",
    "import torch_geometric.nn as gnn\n",
    "import nni\n",
    "from nni.retiarii import model_wrapper"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv2d(in_ch, in_ch, kernel_size=3, groups=in_ch)\n",
    "        self.pointwise = nn.Conv2d(in_ch, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "\n",
    "\n",
    "@model_wrapper\n",
    "class ModelSpace(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        # LayerChoice is used to select a layer between Conv2d and DwConv.\n",
    "        self.conv2 = nn.LayerChoice([\n",
    "            nn.Conv2d(32, 64, 3, 1),\n",
    "            DepthwiseSeparableConv(32, 64)\n",
    "        ])\n",
    "        # ValueChoice is used to select a dropout rate.\n",
    "        # ValueChoice can be used as parameter of modules wrapped in `nni.retiarii.nn.pytorch`\n",
    "        # or customized modules wrapped with `@basic_unit`.\n",
    "        self.dropout1 = nn.Dropout(nn.ValueChoice([0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        feature = nn.ValueChoice([64, 128, 256])\n",
    "        self.fc1 = nn.Linear(9216, feature)\n",
    "        self.fc2 = nn.Linear(feature, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(self.conv2(x), 2)\n",
    "        x = torch.flatten(self.dropout1(x), 1)\n",
    "        x = self.fc2(self.dropout2(F.relu(self.fc1(x))))\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output\n",
    "model_space = ModelSpace()\n",
    "print(model_space)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@model_wrapper\n",
    "class MySpace(nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, hidden=20):\n",
    "        super().__init__()\n",
    "        #self.conv1 = GCNConv(num_node_features, 16)\n",
    "        #self.conv2 = GCNConv(16, num_classes)\n",
    "        self.conv1 = nn.LayerChoice([\n",
    "            #gnn.GATconv(num_node_features, hidden),\n",
    "            gnn.GCNConv(num_node_features, hidden),\n",
    "            #gnn.GINconv(num_node_features, hidden),\n",
    "            gnn.ChebConv(num_node_features, hidden, K=2),\n",
    "            gnn.SAGEConv(num_node_features, hidden)\n",
    "        ])\n",
    "        self.dropout1 = nn.Dropout(nn.ValueChoice([0.1, 0.25, 0.5, 0.75]))  # choose dropout rate from 0.25, 0.5 and 0.75\n",
    "        self.conv2 = nn.LayerChoice([\n",
    "            #gnn.GATconv(hidden, num_classes),\n",
    "            gnn.GCNConv(hidden, num_classes),\n",
    "            #gnn.GINconv(hidden, num_classes),\n",
    "            gnn.ChebConv(hidden, num_classes, K=2),\n",
    "            gnn.SAGEConv(hidden, num_classes)\n",
    "        ])\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x, training=self.training)\n",
    "        x = F.softmax(x, dim=1)\n",
    "\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MySpace(\n",
      "  (conv1): LayerChoice([GCNConv(3703, 20), ChebConv(3703, 20, K=2, normalization=sym), SAGEConv(3703, 20, aggr=mean)], label='model_1')\n",
      "  (dropout1): Dropout(p=0.1, inplace=False)\n",
      "  (conv2): LayerChoice([GCNConv(20, 6), ChebConv(20, 6, K=2, normalization=sym), SAGEConv(20, 6, aggr=mean)], label='model_3')\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "my_space = MySpace(dataset.num_node_features, dataset.num_classes)\n",
    "print(my_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nni.retiarii.strategy as strategy\n",
    "search_strategy = strategy.Random(dedup=True)  # dedup=False if deduplication is not wanted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, myprint=False):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    loss_function = torch.nn.CrossEntropyLoss().to(device)\n",
    "    model.train()\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = loss_function(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if myprint and epoch % 20 == 0:\n",
    "            print(\"epoch {}, loss = {}\".format(epoch, loss))\n",
    "    model.eval()\n",
    "    pred = model(data).argmax(dim=1)\n",
    "    correct = (pred[data.val_mask] == data.y[data.val_mask]).sum()\n",
    "    acc = int(correct) / int(data.val_mask.sum())\n",
    "    if myprint:\n",
    "        print(f'Accuracy: {acc:.4f}')\n",
    "    #return acc\n",
    "    nni.report_final_result(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nni.retiarii.evaluator import FunctionalEvaluator\n",
    "evaluator = FunctionalEvaluator(eval_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom nni.nas.experiment import NasExperiment\\nexp = NasExperiment(my_space, evaluator, search_strategy)\\nexp.config.max_trial_number = 20   # spawn 4 trials at most\\nexp.config.trial_concurrency = 1\\n\\nexp.config.trial_gpu_number = 1\\nexp.config.training_service.use_active_gpu = True\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nni.retiarii.experiment.pytorch import RetiariiExperiment, RetiariiExeConfig\n",
    "exp = RetiariiExperiment(my_space, evaluator, [], search_strategy)\n",
    "exp_config = RetiariiExeConfig('local')\n",
    "exp_config.experiment_name = 'mnist_search'\n",
    "exp_config.max_trial_number = 20   # spawn 4 trials at most\n",
    "exp_config.trial_concurrency = 1  # will run two trials concurrently\n",
    "\n",
    "exp_config.trial_gpu_number = 1\n",
    "exp_config.training_service.use_active_gpu = True\n",
    "'''\n",
    "from nni.nas.experiment import NasExperiment\n",
    "exp = NasExperiment(my_space, evaluator, search_strategy)\n",
    "exp.config.max_trial_number = 20   # spawn 4 trials at most\n",
    "exp.config.trial_concurrency = 1\n",
    "\n",
    "exp.config.trial_gpu_number = 1\n",
    "exp.config.training_service.use_active_gpu = True\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-06-04 23:04:14] \u001b[32mCreating experiment, Experiment ID: \u001b[36medm9f0yq\u001b[0m\n",
      "[2023-06-04 23:04:14] \u001b[32mStarting web server...\u001b[0m\n",
      "[2023-06-04 23:04:16] \u001b[32mSetting up...\u001b[0m\n",
      "[2023-06-04 23:04:16] \u001b[32mWeb portal URLs: \u001b[36mhttp://169.254.189.172:8081 http://169.254.239.17:8081 http://169.254.159.216:8081 http://172.20.3.190:8081 http://169.254.29.87:8081 http://169.254.244.73:8081 http://127.0.0.1:8081\u001b[0m\n",
      "[2023-06-04 23:04:16] \u001b[32mDispatcher started\u001b[0m\n",
      "[2023-06-04 23:04:17] \u001b[32mStart strategy...\u001b[0m\n",
      "[2023-06-04 23:04:17] \u001b[32mSuccessfully update searchSpace.\u001b[0m\n",
      "[2023-06-04 23:04:17] \u001b[32mRandom search running in fixed size mode. Dedup: on.\u001b[0m\n",
      "[2023-06-04 23:15:08] \u001b[33mWARNING: KeyboardInterrupt detected\u001b[0m\n",
      "[2023-06-04 23:15:08] \u001b[32mStopping experiment, please wait...\u001b[0m\n",
      "[2023-06-04 23:15:08] \u001b[32mDispatcher exiting...\u001b[0m\n",
      "[2023-06-04 23:15:10] \u001b[32mDispatcher terminiated\u001b[0m\n",
      "[2023-06-04 23:15:10] \u001b[32mExperiment stopped\u001b[0m\n",
      "[2023-06-04 23:15:10] \u001b[32mSearch process is done, the experiment is still alive, `stop()` can terminate the experiment.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "exp.run(exp_config, 8081)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
